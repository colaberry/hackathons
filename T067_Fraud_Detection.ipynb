{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s1",
     "content"
    ]
   },
   "source": [
    "\n",
    "                \n",
    "## Alpha Solutions Fraud Detection  \n",
    "                \n",
    "## Overview of Fraud Detection\n",
    "### Fraud is the event of illegal access or execution of a transaction. Fraud modeling is the process where large amounts of transactional data is analyzed to identify observations which do not generally follow the regular patterns. Due to this nature of the problem, anamoly detection and some classification techniques are most suited to analyze such problems and draw valuable insights.\n",
    "## Problem Statement\n",
    "### A company Alpha solutions provides fraud detection products, solutions and services to financial businesses. One such financial client has many credit card transactions that are provided as the training data. They want the Financial Data Scientist to build models using the available training data.\n",
    "## Dataset\n",
    "### Dataset consists of 5 variables\n",
    "### F:Fraud,G:Gas.J:Jewellery,S:Sex,A:Age\n",
    "### Dataset consits of 1000 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s1",
     "ce"
    ]
   },
   "outputs": [],
   "source": [
    "#initial_code, the code written here will be shown to user, write here initial setup to help user get started.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataframe=pd.read_csv('fraud_data.csv')\n",
    "dataframe.head(10)\n",
    "x=dataframe.iloc[:,[0,1,2,4]]\n",
    "y=dataframe.iloc[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s1",
     "hint"
    ]
   },
   "source": [
    "hint, write any hint here for the above question.\n",
    "dataframe=pd.read_csv('fraud_data.csv')\n",
    "dataframe.head(10)\n",
    "x=dataframe.iloc[:,[0,1,2,4]]\n",
    "y=dataframe.iloc[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "s1",
     "ans"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-974095dba5ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#answer, write code which is a solution for above question.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m### We can observe four features S,A,F,J,G and we have no information about them with us.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m### Therefore let us condiser S,A,G,J as  independent variables and J as dependent variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m## Split the dataframe into independent and dependent features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "#answer, write code which is a solution for above question.\n",
    "dataframe.head(10)\n",
    "### We can observe four features S,A,F,J,G and we have no information about them with us.\n",
    "### Therefore let us condiser S,A,G,J as  independent variables and J as dependent variables.\n",
    "## Split the dataframe into independent and dependent features\n",
    "y.head()\n",
    "## Data preprocessing\n",
    "### Feaures Scaling: Not required as all the values are confined to very small range\n",
    "### Missing Data:Not required as all the values are present and there are no missing values\n",
    "### Encoding categorical variables: Not required as all the features are already encoded\n",
    "## Splitting data into training and testing datasets\n",
    "### It is essential to test our model on data that is not trained in order to know the real power of our model\n",
    "### Therefore we are splitting the data into two sets that is test set and train set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "# let us draw some comparisons from the data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x_train['S'], y_train, color = 'red')\n",
    "plt.plot(x_train['S'],y_train , color = 'blue')\n",
    "plt.title('Graph between S and G')\n",
    "plt.xlabel('SEX')\n",
    "plt.ylabel('JEWELLERY')\n",
    "plt.show()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x_train['A'], y_train, color = 'red')\n",
    "plt.plot(x_train['A'],y_train , color = 'green')\n",
    "plt.title('Graph between A and J')\n",
    "plt.xlabel('AGE')\n",
    "plt.ylabel('JEWELLERY')\n",
    "plt.show()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x_train['F'], y_train, color = 'red')\n",
    "plt.plot(x_train['F'],y_train , color = 'yellow')\n",
    "plt.title('Graph between F and J')\n",
    "plt.xlabel('FRAUD')\n",
    "plt.ylabel('JEWELLERY')\n",
    "plt.show()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x_train['G'], y_train, color = 'red')\n",
    "plt.plot(x_train['G'],y_train , color = 'blue')\n",
    "plt.title('Graph between J and G')\n",
    "plt.xlabel('GAS')\n",
    "plt.ylabel('JEWELLERY')\n",
    "plt.show()\n",
    "## Fitting the dataset in logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier_logisticreg=LogisticRegression()\n",
    "classifier_logisticreg.fit(x_train,y_train)\n",
    "## Predicting the y values using logistic regression model \n",
    "y_pred_logisticreg = classifier_logisticreg.predict(x_test)\n",
    "## To evaluate number of correct and wrong predictions, we can use the confusion matrix \n",
    "## Confusion matrix returns a 2x2 matrix \n",
    "## First row first element and second row second element give the number of correct predictions while the remaining two are the wrong predicitons.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_logisticreg = confusion_matrix(y_test, y_pred_logisticreg)\n",
    "cm_logisticreg\n",
    "## Confusion matrix for logistic regression returned 1895 correct predictions and 105 wrong predictions. \n",
    "## Predicting the y values using Naive Bayes Algorithm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier_nb=GaussianNB()\n",
    "classifier_nb.fit(x_train,y_train)\n",
    "y_pred_nb = classifier_nb.predict(x_test)\n",
    "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "cm_nb\n",
    "## Confusion matrix returned 1877 correct predictions \n",
    "## Predicting the y values using support vector machine model\n",
    "from sklearn.svm import SVC\n",
    "classifier_svc=SVC(kernel='rbf')\n",
    "classifier_svc.fit(x_train,y_train)\n",
    "y_pred_svc=classifier_svc.predict(x_test)\n",
    "cm_svc=confusion_matrix(y_test, y_pred_svc)\n",
    "cm_svc\n",
    "## Confusion matrix for Support vector machine  returned 1895 correct predictions\n",
    "\n",
    "## Predicting the y_test values using decision tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier_dec=DecisionTreeClassifier(criterion='entropy')\n",
    "classifier_dec.fit(x_train,y_train)\n",
    "y_pred_dec=classifier_dec.predict(x_test)\n",
    "cm_dec=confusion_matrix(y_test, y_pred_dec)\n",
    "cm_dec\n",
    "## Total number of correct predictions using decision tree is 1895\n",
    "## RandomForestClassifer  alogorithm for predicting\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier_rand=RandomForestClassifier(n_estimators=500,criterion='entropy',random_state=0)\n",
    "classifier_rand.fit(x_train,y_train)\n",
    "\n",
    "y_pred_rand=classifier_rand.predict(x_test)\n",
    "cm_rand=confusion_matrix(y_test, y_pred_rand)\n",
    "cm_rand\n",
    "## Total number of correct predictions using Random forest is 1895\n",
    "## Finding accuracy of model\n",
    "# the accuracy can be calculated as\n",
    "accuracy=(1727+168)/(1727+168+97+8)\n",
    "accuracy\n",
    "## Accuracy of the model is 94%\n",
    "# Conclusion\n",
    "## From the above observations , we can come to a conclusion that the all the models except naive bayes are giving the same results and hence any one of the above except naive bayes can be used to predict. "
   ]
  }
 ],
 "metadata": {
  "executed_sections": [],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}