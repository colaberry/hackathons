{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s1",
     "content"
    ]
   },
   "source": [
    "# Air Quality Analysis\n",
    "                \n",
    "## About the dataset\n",
    "                \n",
    "      All of this data comes from EPA’s Air Quality System (AQS). Data collection agencies report their data to EPA via this system and it calculates several types of aggregate (summary) data for EPA internal use. This includes daily and annual summaries, but not monthly summaries, as these are not routinely needed by EPA. More details can be found at: https://aqs.epa.gov/aqsweb/airdata/FileFormats.html\n",
    "      \n",
    "      \n",
    "### Recommended reading:\n",
    "      Lesson on Dataframes in Junior Data Scientist/Data Analyst course on Refactored Platform\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html \n",
    "\n",
    "      \n",
    "### Loading the data \n",
    "    The data can be loaded using read_csv command.\n",
    "    Print the first 5 rows of air_df dataframe.\n",
    "    Assign it to x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "has_completed": true,
    "tags": [
     "s1",
     "ce"
    ]
   },
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "#Reading data from EPA's Air quality Control(AQS)\n",
    "air_df=pd.read_csv(\"https://raw.githubusercontent.com/colaberry/data/master/8hour_42101_2017_10K.csv\")\n",
    "\n",
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s1",
     "hint"
    ]
   },
   "source": [
    "Hint: use head() function to print first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s1",
     "ans"
    ]
   },
   "outputs": [],
   "source": [
    "x=air_df.head()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s1",
     "hid"
    ]
   },
   "outputs": [],
   "source": [
    "#this is assertion block which verifies the solution.\n",
    "\n",
    "try:\n",
    "    def verify_answer():\n",
    "        \"\"\"\n",
    "        enter your verification code here.\n",
    "        return true if your checks pass\n",
    "        eg: \n",
    "        if  var>100: \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \"\"\"\n",
    "        if x.iat[0,16] == 6:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    ref_assert_var = verify_answer()\n",
    "except Exception as e:\n",
    "    print('Your assertion block throws error: ' + str(e))\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        print('continue')\n",
    "    else:\n",
    "        print('The answer did not pass the test.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s2",
     "content"
    ]
   },
   "source": [
    "## Exploratory data analysis.\n",
    "\n",
    "## Observing and Preparing data from dataset.\n",
    "      \n",
    "       Exploratory data analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often with visual methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task.\n",
    "       There are a number of tools that are useful for EDA, but EDA is characterized more by the attitude taken than by particular techniques.\n",
    "\n",
    "       Typical graphical techniques used in EDA are Box plot,Histogram,Multi-vari chart and Scatter plot.\n",
    "      \n",
    "       we have to examine the dataset with information from EDA as well as using other statistical methods. The logistic regression algorithm is also a supervised learning technique.\n",
    "       \n",
    "### Excercise\n",
    "    Lets plot the number of observations(Observation Count) of first 8 rows.\n",
    "    Take the values of Observation Count and store it in variable 'x'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "has_completed": true,
    "tags": [
     "s2",
     "ce"
    ]
   },
   "outputs": [],
   "source": [
    "#Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s2",
     "hint"
    ]
   },
   "source": [
    "Hint: Use distplot() function on Observation Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s2",
     "ans"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "x=air_df.head(n=8)['Observation Count']\n",
    "sns.distplot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s2",
     "hid"
    ]
   },
   "outputs": [],
   "source": [
    "#Assertion Block\n",
    "try:\n",
    "    def verify_answer():\n",
    "        \"\"\"\n",
    "        enter your verification code here.\n",
    "        return true if your checks pass\n",
    "        eg: \n",
    "        if  var>100: \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \"\"\"\n",
    "        if x[0]==6:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    ref_assert_var = verify_answer()\n",
    "except Exception as e:\n",
    "    print('Your assertion block throws error: ' + str(e))\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        print('continue')\n",
    "    else:\n",
    "        print('The answer did not pass the test.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s3",
     "content"
    ]
   },
   "source": [
    "## Data visualization\n",
    "\n",
    "        Python is a good language for doing data analysis, primarily because of the fantastic ecosystem of data-centric Python packages. Pandas is one of those packages, and makes importing and analyzing data much easier.\n",
    "        \n",
    "        One of the most useful library in python is matplotlib.Matplotlib is a Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms.\n",
    "        \n",
    "        Matplotlib can be used in Python scripts, the Python and IPython shells, the Jupyter notebook, web application servers, and four graphical user interface toolkits. for more information about this library visit https://matplotlib.org/\n",
    "\n",
    "### Excercise\n",
    "        Plotting Scatter plot between 'Observation Count' and 'Mean Including All Data'\n",
    "        Store Observation Count values in variable 'f1' and Mean Including All Data as 'f2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "has_completed": true,
    "tags": [
     "s3",
     "ce"
    ]
   },
   "outputs": [],
   "source": [
    "#write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s3",
     "hint"
    ]
   },
   "outputs": [],
   "source": [
    "Hint: use scatter() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s3",
     "ans"
    ]
   },
   "outputs": [],
   "source": [
    "f1=air_df['Observation Count'].values\n",
    "f2=air_df['Mean Including All Data'].values\n",
    "plt.scatter(f1, f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s3",
     "hid"
    ]
   },
   "outputs": [],
   "source": [
    "#Assertion Block\n",
    "try:\n",
    "    def verify_answer():\n",
    "        \"\"\"\n",
    "        enter your verification code here.\n",
    "        return true if your checks pass\n",
    "        eg: \n",
    "        if  var>100: \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \"\"\"\n",
    "        if f1[3]==8:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    ref_assert_var = verify_answer()\n",
    "except Exception as e:\n",
    "    print('Your assertion block throws error: ' + str(e))\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        print('continue')\n",
    "    else:\n",
    "        print('The answer did not pass the test.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s4",
     "content"
    ]
   },
   "source": [
    "# Clustering on dataset.\n",
    "\n",
    "## Introduction to Clustering\n",
    "    \n",
    "    clustering is a type of Unsupervised learning. This is very often used when you don’t have labeled data. K-Means Clustering is one of the popular clustering algorithms. The goal of this algorithm is to find groups(clusters) in the given data. \n",
    "\n",
    "    Finding groups based on a criterion in the dataset is called clustering. The criterion could be a spatial distribution involving distance between nearby points or could involve another metric such as density based on presence of neighbors. A basic clustering algorithm is called k-means clustering which is a spatial clustering algorithm.\n",
    "\n",
    "\n",
    "## k-means clustering\n",
    "\n",
    "    k-means clustering takes in k number of clusters that could potentially exist in a data set and outputs associations of each member of the dataset to a cluster in the range [1, k]. k-means initially randomly associates each data point to a random cluster in the range [1, k] and determines the centroid of each cluster.\n",
    "    \n",
    "    Later, in an iterative manner, the members associations as well as cluster centroids of k clusters are updated till a convergence criterion is achieved.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "     Take n_cluster=5 , init = 'k-means++', n_init=10 , max_iter=300\n",
    "      \n",
    "     Assign KMean cluster column to x and plot histogram of x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "has_completed": true,
    "tags": [
     "s4",
     "ce"
    ]
   },
   "outputs": [],
   "source": [
    "features = ['Observation Count','Mean Including All Data','Mean Excluding All Flagged Data','Mean Excluding Concurred Flags']\n",
    "#write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s4",
     "hint"
    ]
   },
   "source": [
    "Hint: Use KMeans() function from Clustering Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s4",
     "ans"
    ]
   },
   "outputs": [],
   "source": [
    "k_means=KMeans(n_clusters=5, init='k-means++', n_init=10, max_iter=300)\n",
    "k_means.fit(air_df[features])\n",
    "\n",
    "KMean=air_df.assign(KMeanCluster=k_means.labels_)\n",
    "KMean['KMeanCluster']\n",
    "\n",
    "x=KMean['KMeanCluster']\n",
    "plt.hist(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s4",
     "hid"
    ]
   },
   "outputs": [],
   "source": [
    "#Assertion Block\n",
    "try:\n",
    "    def verify_answer():\n",
    "        \"\"\"\n",
    "        enter your verification code here.\n",
    "        return true if your checks pass\n",
    "        eg: \n",
    "        if  var>100: \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \"\"\"\n",
    "        if x[3]==3:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    ref_assert_var = verify_answer()\n",
    "except Exception as e:\n",
    "    print('Your assertion block throws error: ' + str(e))\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        print('continue')\n",
    "    else:\n",
    "        print('The answer did not pass the test.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s5",
     "content"
    ]
   },
   "source": [
    "## Agglomerative Clustering\n",
    "       \n",
    "       In agglomerative clustering is that each node starts in its own cluster, and recursively merges with the pair of clusters that minimally increases a given linkage distance. The main advantage of agglomerative clustering (and hierarchical clustering in general) is that you don’t need to specify the number of clusters.\n",
    "       \n",
    "       That of course, comes with a price: performance. But, in scikit’s implementation, you can specify the number of clusters to assist the algorithm’s performance.\n",
    "       \n",
    "### Exercise\n",
    "    Take n_clusters=5, linkage=\"ward\"\n",
    "    \n",
    "    Assign Agglomerative cluster column to y and plot histogram of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "has_completed": true,
    "tags": [
     "s5",
     "ce"
    ]
   },
   "outputs": [],
   "source": [
    "#write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s5",
     "hint"
    ]
   },
   "source": [
    "Hint: Use AgglomerativeClustering() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s5",
     "ans"
    ]
   },
   "outputs": [],
   "source": [
    "agglomerative=AgglomerativeClustering(n_clusters=5, linkage=\"ward\")\n",
    "agglomerative.fit(air_df[features])\n",
    "\n",
    "Agglo=air_df.assign(AggloCluster=agglomerative.labels_)\n",
    "Agglo['AggloCluster']\n",
    "\n",
    "y=Agglo['AggloCluster']\n",
    "plt.hist(y)"
   ]
  }
 ],
 "metadata": {
  "executed_sections": [],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}