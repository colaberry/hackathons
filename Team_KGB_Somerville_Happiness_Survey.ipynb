{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s1",
     "content"
    ]
   },
   "source": [
    "# University of Texas, Dallas - Hackathon Oct 2017\n",
    "\n",
    "\n",
    "## Problem 3: Somerville Happiness Survey\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s1",
     "ce"
    ]
   },
   "outputs": [],
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "s1",
     "hint"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "\n",
    "#Loading Data\n",
    "city = pd.read_csv('https://data.somervillema.gov/api/views/yevj-2b33/rows.csv')\n",
    "city.describe()\n",
    "city.groupby(by='Year',axis=0).count()\n",
    "\n",
    "#Divided the dataset by year\n",
    "city_2011 = city[city.Year == 2011]\n",
    "city_2013 = city[city.Year == 2013]\n",
    "city_2015 = city[city.Year == 2015]\n",
    "\n",
    "#Creating a list of the columns with all values as NA for year 2011\n",
    "na_col_list = city_2011.columns[city_2011.isnull().all()].tolist()\n",
    "\n",
    "city_2011_nonull = city_2011.drop(na_col_list,axis=1)\n",
    "\n",
    "city_2011_nonull.shape\n",
    "\n",
    "city_2011_nonull.head(5)\n",
    "contents2011 = city_2011_nonull.columns\n",
    "contents2011\n",
    "\n",
    "###Dropping the columns with null values for Year 2013 and 2015\n",
    "### This is for the 2013 year\n",
    "na_col_list = city_2013.columns[city_2013.isnull().all()].tolist()\n",
    "city_2013_nonull = city_2013.drop(na_col_list,axis=1)\n",
    "\n",
    "### This is for the 2015 year\n",
    "na_col_list = city_2015.columns[city_2015.isnull().all()].tolist()\n",
    "city_2015_nonull = city_2015.drop(na_col_list,axis=1)\n",
    "\n",
    "contents2015 = city_2015_nonull.columns\n",
    "\n",
    "### Keeping the columns which are common in all years\n",
    "\n",
    "rem2011 = ['The.availability.of.affordable.housing_2011',\n",
    "           'How.would.you.rate.the.following..The.beauty.or.physical.setting_2011',\n",
    "           'When.making.decisions..are.you.more.likely.to.seek.advice.or.decide.for.yourself._2011.',\n",
    "           'In.general..how.similar.are.you.to.other.people.you.know._2011',\n",
    "            'Marital.status._2011']\n",
    "\n",
    "city_2011_raw = city_2011_nonull.drop(rem2011, axis=1)\n",
    "\n",
    "city_2011_raw.shape\n",
    "\n",
    "rem2013 = ['How.would.you.rate.the.following..The.cost.of.housing.',\n",
    "           'How.would.you.rate.the.following..The.beauty.or.physical.setting.of.Somerville_2013',\n",
    "           'How.satisfied.are.you.with.your.neighborhood.',\n",
    "           'How.would.you.rate.the.following..The.availability.of.social.community.events',\n",
    "           'How.safe.do.you.feel.walking.in.your.neighborhood.at.night_2013',\n",
    "           'How.would.you.rate.the.following..The.maintenance.of.streets..sidewalks..and..squares_2013',\n",
    "           'How.satisfied.are.you.with.the.beauty.or.physical.setting.of.your.neighborhood.',\n",
    "           'How.satisfied.are.you.with.the.appearance.of.parks.in.your.neighborhood._2013',\n",
    "           'Are.you.of.Hispanic..Latino..or.Spanish.origin._2013',\n",
    "           'Do.you.have.children.age.18.or.younger.who.live.with.you.',\n",
    "           'Do.you.plan.to.move.away.from.Somerville.in.the.next.two.years.',\n",
    "           'What.neighborhood.do.you.live.in.', 'Are.you.a.student.', 'Ward',\n",
    "           'Precinct']\n",
    "\n",
    "city_2013_raw = city_2013_nonull.drop(rem2013,axis = 1)\n",
    "\n",
    "### Delelting the columns from 2015 which are not there in 2011\n",
    "\n",
    "rem2015 = ['How.proud.are.you.to.be.a.Somerville.resident._2015',\n",
    "          'How.would.you.rate.the.following..The.availability.of.information.about.city.services._2015',\n",
    "          'How.would.you.rate.the.following..The.cost.of.housing.',\n",
    "          'How.would.you.rate.the.following..The.maintenance.of.streets.and.sidewalks_2015',\n",
    "          'How.would.you.rate.the.following..The.availability.of.social.community.events',\n",
    "          'How.safe.do.you.feel.walking.in.your.community.at.night._2015',\n",
    "          'How.satisfied.are.you.with.the.beauty.or.physical.setting.of.your.neighborhood.',\n",
    "          'How.satisfied.are.you.with.the.appearance.of.parks.and.squares.in.your.neighborhood.',\n",
    "          'What.language..other.than.English..do.you.speak.at.home._2015',\n",
    "          'Do.you.have.children.age.18.or.younger.who.live.with.you.',\n",
    "          'Describe.your.housing.status.in.Somerville.',\n",
    "          'Do.you.plan.to.move.away.from.Somerville.in.the.next.two.years.',\n",
    "          'What.neighborhood.do.you.live.in.', 'Are.you.a.student.', 'Ward',\n",
    "          'How.satisfied.are.you.with.your.neighborhood.',\n",
    "          'Precinct']\n",
    "\n",
    "city_2015_raw = city_2015_nonull.drop(rem2015, axis=1)\n",
    "\n",
    "city_2015_raw.shape\n",
    "\n",
    "### Modifying the column names for better data consistency\n",
    "\n",
    "renamed_cols = ['Combined_ID','year','happiness_index','satisfaction_life_index','satisfaction_place_index','quality_public_schools',\n",
    "'local_police_effectiveness','sex','age','race','time_lived','annual_household_income']\n",
    "\n",
    "city_2011_raw.columns = renamed_cols\n",
    "\n",
    "city_2015_raw.columns = renamed_cols\n",
    "\n",
    "city_2013_raw.columns = renamed_cols\n",
    "\n",
    "### Merged the three datasets \n",
    "\n",
    "data = [city_2011_raw,city_2013_raw,city_2015_raw]\n",
    "\n",
    "city_final = pd.concat(data)\n",
    "\n",
    "city_final.shape\n",
    "\n",
    "#### Dropping the combinedID columns as Column ID is not significant for the model\n",
    "\n",
    "city_final1 = city_final.drop('Combined_ID',axis=1)\n",
    "\n",
    "\n",
    "### Dropping the rows having Null target value \n",
    "\n",
    "city_final1 = city_final1[city_final1.happiness_index.notnull()]\n",
    "\n",
    "### Removing non-numeric values from the entire dataset\n",
    "\n",
    "df = city_final1.applymap(lambda x: 'NA' if (x == '9*' or x == 'R' or x == 'i' or x == 'X' or x == 'r' or x == 'F' or x == 'n'\n",
    "                                             or x == 'e' or x == '3f' or x == '5/27/2011' or x == '5/19/2011'\n",
    "                                            or x == '6/6/2011' or x == '6/1/2011') else x)\n",
    "\n",
    "len(df)\n",
    "\n",
    "df1 = df.dropna(axis=0,how='any')\n",
    "\n",
    "len(df1)\n",
    "\n",
    "### Extracting the Target Variable\n",
    "\n",
    "city_final_target = df1['happiness_index']\n",
    "\n",
    "city_final_var = df1.drop('happiness_index',axis=1)\n",
    "\n",
    "### Creating the dummy variables for the categorical variables\n",
    "\n",
    "city_final_var = pd.get_dummies(city_final_var)\n",
    "city_final_var.shape\n",
    "\n",
    "### Splitting the dataset into Train and Test sets: 70 - 30\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(city_final_var, city_final_target , test_size=0.3, random_state=0)\n",
    "\n",
    "happiness_model1 = LogisticRegression(random_state=0)\n",
    "\n",
    "happiness_model = happiness_model1.fit(X_train,y_train)\n",
    "\n",
    "### Building Confusion Matrix\n",
    "\n",
    "Y_HAT = happiness_model.predict(X_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test,Y_HAT)\n",
    "\n",
    "print(conf_matrix)\n",
    "\n",
    "### Calculating the Accuracy of the model\n",
    "\n",
    "acc = happiness_model.score(X_test,y_test)\n",
    "print('Accuracy of logistic regression classifier on test set {:.2f} '.format(happiness_model.score(X_test,y_test)))\n",
    "\n",
    "### Calculating Recall and Precision\n",
    "print (metrics.classification_report(y_test, Y_HAT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "s1",
     "ans"
    ]
   },
   "outputs": [],
   "source": [
    "#this is assertion block which verifies the solution.\n",
    "\n",
    "try:\n",
    "    def verify_answer(x):\n",
    "\n",
    "         \n",
    "        if x > .50: \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "\n",
    "    ref_assert_var = verify_answer(acc)\n",
    "except Exception as e:\n",
    "    print('Your assertion block throws error: ' + str(e))\n",
    "else:\n",
    "    if ref_assert_var:\n",
    "        print('Well done team')\n",
    "    else:\n",
    "        print('The answer did not pass the test.')"
   ]
  }
 ],
 "metadata": {
  "executed_sections": [],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}